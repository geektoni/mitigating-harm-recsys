{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7d2604f-faf9-4870-9594-1949c96e6ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49072431-0a19-4500-99d3-e2eafb5cf9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(font_scale=1.2,\n",
    "        style=\"ticks\",\n",
    "        rc={\n",
    "        \"text.usetex\": True,\n",
    "        'text.latex.preamble': r'\\usepackage{amsfonts}',\n",
    "        \"font.family\": \"serif\",\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eb5e381-e591-47a1-adad-73d0b234aad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_files_to_dataframe(directory, columns=None):\n",
    "    \"\"\"\n",
    "    Reads all CSV files in the specified directory and combines them into a single pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        directory (str): The path to the directory containing the CSV files.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the combined data from all CSV files.\n",
    "    \"\"\"\n",
    "    # List to store dataframes\n",
    "    dataframes = []\n",
    "\n",
    "    # Iterate through all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.csv'):   \n",
    "            if \"random\" in filename:\n",
    "                continue\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            print(f\"Loading file: {filepath}\")\n",
    "            # Read the CSV file and append to the list\n",
    "            dataframes.append(pd.read_csv(filepath, usecols=columns))\n",
    "\n",
    "    # Concatenate all dataframes into one\n",
    "    combined_dataframe = pd.concat(dataframes, ignore_index=True)\n",
    "    return combined_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "00192ebd-4964-41f0-9710-283aeace4d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: KuaiRand-Harm/data/log_standard_4_08_to_4_21_27k_part2.csv\n",
      "Loading file: KuaiRand-Harm/data/log_standard_4_08_to_4_21_27k_part1.csv\n",
      "Loading file: KuaiRand-Harm/data/log_standard_4_22_to_5_08_27k_part1.csv\n",
      "Loading file: KuaiRand-Harm/data/log_standard_4_22_to_5_08_27k_part2.csv\n"
     ]
    }
   ],
   "source": [
    "df = load_csv_files_to_dataframe(\"KuaiRand-Harm/data\", [\"play_time_ms\", \"is_hate\", \"duration_ms\", \"video_id\", \"is_click\", \"user_id\", \"date\", \"hourmin\", \"time_ms\", \"is_rand\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f9bf15ca-57f5-4c6d-897e-986508449d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.to_datetime(df[\"time_ms\"], unit='ms').dt.tz_localize('Asia/Singapore').dt.tz_convert(\"ETC/GMT-8\")\n",
    "df[\"timestamp\"] = dt\n",
    "df.drop(columns=[\"date\", \"hourmin\", \"time_ms\"], inplace=True)\n",
    "df = df[df.is_click == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5683b717-0ba3-4023-a780-82e6d722b073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total interaction size:  24462781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_875433/596056597.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"fraction_play_time\"] = df.play_time_ms/df.duration_ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final interaction size:  18950714\n",
      "Reduction 0.22532462682799637\n",
      "Unique videos:  3875888\n"
     ]
    }
   ],
   "source": [
    "# Filter a bit to ensure we have reasonable data\n",
    "original_size = len(df)\n",
    "print(\"Total interaction size: \", len(df))\n",
    "\n",
    "# Keep only elements with a duration greater than zero.\n",
    "df = df[df.duration_ms > 0]\n",
    "df[\"fraction_play_time\"] = df.play_time_ms/df.duration_ms\n",
    "\n",
    "# Remove users which now do not have any negative video flagged\n",
    "harmful_users = df[df['is_hate'] == 1]['user_id'].unique()\n",
    "df = df[df['user_id'].isin(harmful_users)]\n",
    "\n",
    "reduction_size = len(df)\n",
    "print(\"Final interaction size: \", len(df))\n",
    "print(\"Reduction\", 1-reduction_size/original_size) # We basically loose around 12 % of interactions\n",
    "print(\"Unique videos: \", len(df.video_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1c4909bb-67fa-46dc-966f-8f6a62515b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify video_ids that have been seen at least twice by one user\n",
    "videos_seen_twice = df.groupby([\"user_id\", \"video_id\"]).size().reset_index(name='count')\n",
    "videos_to_keep = videos_seen_twice[videos_seen_twice['count'] >= 2][\"video_id\"].unique()\n",
    "\n",
    "# Filter the original dataframe to include all rows with those video_ids\n",
    "df = df[df[\"video_id\"].isin(videos_to_keep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9657ecad-a1fa-493e-b016-991eb56c0f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final interaction length:  3645375\n",
      "[*] Reduction 0.8509828052664985\n"
     ]
    }
   ],
   "source": [
    "print(\"Final interaction length: \", len(df))\n",
    "print(\"[*] Reduction\", 1-len(df)/original_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "78595f6c-d121-457b-8147-a411dd2573e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-index all users and videos, since we might have removed some\n",
    "df['user_id'], mapping_user_id = pd.factorize(df['user_id'])\n",
    "df['video_id'], mapping_video_id = pd.factorize(df['video_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "74434829-7615-4102-b5c8-36b8b2358fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we separate repeated and non-repeated videos\n",
    "df = df.sort_values(by=[\"user_id\", \"video_id\", \"timestamp\"])\n",
    "\n",
    "# Create DataFrame with only the first repeated occurrences\n",
    "repeated_videos = df[df.duplicated(subset=[\"user_id\", \"video_id\"], keep=False)].groupby([\"user_id\", \"video_id\"]).nth(1).reset_index()\n",
    "\n",
    "# Create DataFrame with videos seen only once\n",
    "seen_once_videos = df.drop_duplicates(subset=[\"user_id\", \"video_id\"], keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7010af89-443e-4198-a9d0-4bca89e72ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_videos.drop(columns=[\"index\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b0d8b8e5-8f4b-4da5-b67f-d01b6f5d2a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(seen_once_videos, repeated_videos[[\"user_id\", \"video_id\", \"is_hate\", \"fraction_play_time\", 'play_time_ms']],\n",
    "                    on=['user_id', 'video_id'],\n",
    "                   how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bfb11a-017a-4966-8051-d985bbd6ee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.rename(columns={\n",
    "    \"is_hate_x\": \"is_hate\",\n",
    "    \"fraction_play_time_x\": \"fraction_play_time\"\n",
    "}, inplace=True)\n",
    "\n",
    "merged_df.to_csv(\"KuaiRand-Harm/training/single_and_repeated_interactions_is_click.csv.gzip\", index=None, compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "harm-recsys",
   "language": "python",
   "name": "harm-recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
